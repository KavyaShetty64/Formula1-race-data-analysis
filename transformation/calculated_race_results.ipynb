{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8b5a4b8-5dd2-405a-890b-02d89cfd300e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text(\"p_file_date\", \"2021-03-21\")\n",
    "v_file_date = dbutils.widgets.get(\"p_file_date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0bb813e9-7ef1-4f3f-a5df-db747979c8f8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[15]: DataFrame[]"
     ]
    }
   ],
   "source": [
    "spark.sql(f\"\"\"\n",
    "              CREATE TABLE IF NOT EXISTS f1_presentation.calculated_race_results\n",
    "              (\n",
    "              race_year INT,\n",
    "              team_name STRING,\n",
    "              driver_id INT,\n",
    "              driver_name STRING,\n",
    "              race_id INT,\n",
    "              position INT,\n",
    "              points INT,\n",
    "              calculated_points INT,\n",
    "              created_date TIMESTAMP,\n",
    "              updated_date TIMESTAMP\n",
    "              )\n",
    "              USING DELTA\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e876956-e305-4b21-b5d6-706872e29ce5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[16]: DataFrame[]"
     ]
    }
   ],
   "source": [
    "spark.sql(f\"\"\"\n",
    "              CREATE OR REPLACE TEMP VIEW race_result_updated\n",
    "              AS\n",
    "              SELECT races.race_year,\n",
    "                     constructors.name AS team_name,\n",
    "                     drivers.driver_id,\n",
    "                     drivers.name AS driver_name,\n",
    "                     races.race_id,\n",
    "                     results.position,\n",
    "                     results.points,\n",
    "                     11 - results.position AS calculated_points\n",
    "                FROM f1_processed.results \n",
    "                JOIN f1_processed.drivers ON (results.driver_id = drivers.driver_id)\n",
    "                JOIN f1_processed.constructors ON (results.constructor_id = constructors.constructor_id)\n",
    "                JOIN f1_processed.races ON (results.race_id = races.race_id)\n",
    "               WHERE results.position <= 10\n",
    "                 AND results.file_date = '{v_file_date}'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe73e159-5ab9-4577-ba55-97d109178f53",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[17]: DataFrame[num_affected_rows: bigint, num_updated_rows: bigint, num_deleted_rows: bigint, num_inserted_rows: bigint]"
     ]
    }
   ],
   "source": [
    "spark.sql(f\"\"\"\n",
    "              MERGE INTO f1_presentation.calculated_race_results tgt\n",
    "              USING race_result_updated upd\n",
    "              ON (tgt.driver_id = upd.driver_id AND tgt.race_id = upd.race_id)\n",
    "              WHEN MATCHED THEN\n",
    "                UPDATE SET tgt.position = upd.position,\n",
    "                           tgt.points = upd.points,\n",
    "                           tgt.calculated_points = upd.calculated_points,\n",
    "                           tgt.updated_date = current_timestamp\n",
    "              WHEN NOT MATCHED\n",
    "                THEN INSERT (race_year, team_name, driver_id, driver_name,race_id, position, points, calculated_points, created_date ) \n",
    "                     VALUES (race_year, team_name, driver_id, driver_name,race_id, position, points, calculated_points, current_timestamp)\n",
    "       \"\"\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "calculated_race_results",
   "widgets": {
    "p_file_date": {
     "currentValue": "2021-04-18",
     "nuid": "f8687f97-7b0c-4506-955d-0066b9bd4da0",
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "2021-03-21",
      "label": null,
      "name": "p_file_date",
      "options": {
       "widgetType": "text",
       "validationRegex": null
      }
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
